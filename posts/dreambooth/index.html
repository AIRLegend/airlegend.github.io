<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="How I generated professional headshots for my LinkedIn profile" /><meta name="author" content="Alvaro" /><meta property="og:locale" content="en" /><meta name="description" content="The other day I was bored, wandering through LinkedIn and realized that I probably needed some new profile pics. You know, the ones very corporate-guys share on their posts. Something cool with a suit and some office-styled background. So I thought: What if I finetune an image generation model on myself and use it to generate them?" /><meta property="og:description" content="The other day I was bored, wandering through LinkedIn and realized that I probably needed some new profile pics. You know, the ones very corporate-guys share on their posts. Something cool with a suit and some office-styled background. So I thought: What if I finetune an image generation model on myself and use it to generate them?" /><link rel="canonical" href="https://airlegend.github.io/posts/dreambooth/" /><meta property="og:url" content="https://airlegend.github.io/posts/dreambooth/" /><meta property="og:site_name" content="Alvaro’s blog" /><meta property="og:image" content="https://i.imgur.com/tChisdZ.png" /><meta property="og:image:height" content="200" /><meta property="og:image:width" content="200" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-11-18T03:33:00+01:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://i.imgur.com/tChisdZ.png" /><meta property="twitter:title" content="How I generated professional headshots for my LinkedIn profile" /><meta name="twitter:site" content="@aalvaroir" /><meta name="twitter:creator" content="@Alvaro" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alvaro"},"dateModified":"2023-11-30T22:39:51+01:00","datePublished":"2023-11-18T03:33:00+01:00","description":"The other day I was bored, wandering through LinkedIn and realized that I probably needed some new profile pics. You know, the ones very corporate-guys share on their posts. Something cool with a suit and some office-styled background. So I thought: What if I finetune an image generation model on myself and use it to generate them?","headline":"How I generated professional headshots for my LinkedIn profile","image":{"width":200,"height":200,"url":"https://i.imgur.com/tChisdZ.png","@type":"imageObject"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://airlegend.github.io/posts/dreambooth/"},"url":"https://airlegend.github.io/posts/dreambooth/"}</script><title>How I generated professional headshots for my LinkedIn profile | Alvaro's blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Alvaro's blog"><meta name="application-name" content="Alvaro's blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" https://avatars.githubusercontent.com/u/9653892?v=4 " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Alvaro's blog</a></div><div class="site-subtitle font-italic">Notes on projects and ideas</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/AIRLegend" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/aalvaroir" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['alvaroibrain','outlook.es'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>How I generated professional headshots for my LinkedIn profile</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 200 200'%3E%3C/svg%3E" data-src="https://i.imgur.com/tChisdZ.png" class="preview-img bg" alt="Preview Image" width="200" height="200" data-proofer-ignore><h1 data-toc-skip>How I generated professional headshots for my LinkedIn profile</h1><div class="post-meta text-muted"><div> By <em> Alvaro </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" data-ts="1700274780" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-11-18 </em> </span> <span> Updated <em class="timeago" data-ts="1701380391" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-11-30 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1287 words"> <em>7 min</em> read</span></div></div></div><div class="post-content"><p>The other day I was bored, wandering through LinkedIn and realized that I probably needed some new profile pics. You know, the ones very corporate-guys share on their posts. Something cool with a suit and some office-styled background. So I thought: What if I finetune an image generation model on myself and use it to generate them?</p><h2 id="how-can-i-generate-photos-of-myself"><span class="mr-2">How can I generate photos of myself?</span><a href="#how-can-i-generate-photos-of-myself" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>Just to begin, there are countless of image generation models, being the most famous Midjourney, DALL-e and Stable Diffusion – being the latter the only one which is public – and we can prompt them to generate custom images! (<a href="https://lexica.art/?q=d8fce142-23e4-4bd9-9ae1-6e32db4d3ddd">see some examples on the Lexica browser</a>)</p><p>Last July, Stability.ai (the company behind the Stable Diffusion models) released the best iteration of their model: <strong>Stable Diffusion XL 1.0</strong> (SDXL from now on), which is a pretty big step forward in quality from its previous “gold-standard model”, Stable Diffusion 1.5.</p><p>So, it would be nice if I could finetune it on several of my photos and use it for generating me in whichever type of pic I wanted.</p><p>But there are a few problems:</p><ol><li>I don’t currently have access to my GPU machine (or any cloud GPU)<li>I don’t want to spend much on this endeavor<li>I don’t have too much time to train a “complex” model on my old Macbook’s CPU.</ol><p>The ideal solution then is to finetune this model on <a href="https://colab.google/">Google Colab</a> – which is the hardest part–, download the weights and run inference anywhere with the prompt I want.</p><h2 id="finetuning-sdxl-10"><span class="mr-2">Finetuning SDXL 1.0</span><a href="#finetuning-sdxl-10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>The first thing we need to do with any ML model is to gather some data. Regardless, with a model such big and complex as SDXL one could expect hundreds or thousands of images to be required, and it wouldn’t be wrong. Yet, there are techniques for easing this requirement, being one of them “<a href="https://arxiv.org/abs/2208.12242">Dreambooth</a>”, which lets anyone finetune their diffusion model using only approximately 5 images (obviously, the more images and the more diverse they are, the better results one will get).</p><h3 id="gathering-the-data"><span class="mr-2">Gathering the data</span><a href="#gathering-the-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>I quickly ran through my phone’s gallery just to collect about 12 photos of myself. Trying to get diverse poses, angles, lightning and backgrounds. I’d probably could have tried using more pics, but I got more-or-less good results with this amount.</p><p><img data-src="https://media.githubusercontent.com/media/airlegend/airlegend.github.io/gh-pages/assets/img/posts/dreambooth/trainingdata.png?raw=/true" alt="training data" data-proofer-ignore></p><p>The next step is to resize them to a common aspect ratio, usually squared. For this I used a generic free photo resizer tool I found on Google, called <a href="https://www.birme.net/?target_width=1024&amp;target_height=1024">BIRME</a> (feel free to use if you want, it’s pretty nice). I personally found better generation results using a size of 1024x1024 pixels, although 512x512 wasn’t too far behind for me and also requires fewer memory (and maybe also faster).</p><p>Once done, download the .zip with all the resized photos.</p><h3 id="finetuning-sdxl-on-google-colab"><span class="mr-2">Finetuning SDXL on Google Colab</span><a href="#finetuning-sdxl-on-google-colab" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>I’ve made a Google Colab notebook with all the training code I wrote.</p><center> <a target="_blank" href="https://colab.research.google.com/github/AIRLegend/notebook-examples/blob/master/dreambooth_lora/GenerateImagesOfYourself.ipynb"> <img data-src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" data-proofer-ignore> </a> </center><p>I used Huggingface’s <a href="https://github.com/huggingface/autotrain-advanced/tree/main">Advanced-Autotrain</a> package, which comes with a very handy script for finetuning SDXL (or any model really) with only one command: <code class="language-plaintext highlighter-rouge">autotrain dreambooth</code>. On top of that, it handles a critical thing for being able to do this on the low memory’s T4 GPU that Colab offers: <a href="https://airlegend.github.io/posts/lora/">using LoRA, which I cover on a previous post</a>.</p><p>The notebook is meant to be self explanatory, but basically, you put your images on the <code class="language-plaintext highlighter-rouge">img/</code> folder, run the training and download the <code class="language-plaintext highlighter-rouge">safetensors</code> file, which contains the LoRA weights of your tuned model. After that, you can run inference with them wherever you want (although the notebook contains a section for doing it).</p><p>SDXL comes with a “Refiner” model which is meant to “fix” inconsistencies the base model made (for example on eyes, hands, text, etc.). However, while on Google Colab, this model cannot be held into memory simultaneously with the base one. We must save the image, restart the session and run the refiner separately, which it’s a bummer.</p><p>If you have Colab Pro, or access to more memory, I encourage you to run both steps. However, in my experience, only with the first one, good results can be attained.</p><p>I should point out, though, that Colab isn’t reliable for long train runs and could kill your session even though you don’t reach the maximum allowed GPU memory consumption. Use the <code class="language-plaintext highlighter-rouge">--checkpointing_steps</code> parameters accordingly to regularly save checkpoints of your progress.</p><h3 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>After having the model trained you can use the “<strong>inference section</strong>” of the same notebook to produce new images given a prompt. I’ve left some placeholder prompt for generating them, but feel free to explore your own! The prompt engineering part is very important (and pretty much alchemy!), having even more impact on the quality than the finetuning step. I’m pretty much a newbie on it, but I learnt quite a few tricks from this nice guide: “<a href="https://stable-diffusion-art.com/prompt-guide/">Stable Diffusion prompt: a definitive guide</a>”. I strongly encourage you check it out!</p><p>Here are some examples of the generations I got with 1k steps of finetuning and the inference parameters on the notebook (the inference time for each image you generate is about 1 minute).</p><p><img data-src="https://media.githubusercontent.com/media/airlegend/airlegend.github.io/gh-pages/assets/img/posts/dreambooth/gridexamples.png?raw=/true" alt="badeyes" width="512" data-proofer-ignore></p><h3 id="bonus-improving-face-quality"><span class="mr-2">BONUS: Improving face quality</span><a href="#bonus-improving-face-quality" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>After generating the photos, sometimes things as the the eyes are not perfect. They can contain artifacts that make obvious the photos are artificially generated. Even running the refiner model those could stay there, which is kind of a bummer, because the rest of the image can look pretty legit! See an example of what I mean:</p><p><img data-src="https://media.githubusercontent.com/media/airlegend/airlegend.github.io/gh-pages/assets/img/posts/dreambooth/badeyes1.png?raw=/true" alt="badeyes" width="250" data-proofer-ignore></p><p>After investigating this issue I came with a technique (that luckily comes with code) called <a href="https://github.com/sczhou/CodeFormer">CodeFormer</a>, which was primarily meant to restore images of faces, but apparently is also commonly used among “generation artists” to fix the faces of their generations.</p><p>You can install it via the instructions on their README, it’s quite straightforward. After doing it, you can fix the faces of your generated images using the following command (replace the <code class="language-plaintext highlighter-rouge">--input-path</code> with one to your own image!)</p><div class="language-plaintext highlighter-rouge"><div class="code-header"><span> </span><button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>python inference_codeformer.py -w 0.5 --input_path /Users/air/Downloads/generated_image-3.png
</pre></table></code></div></div><p>As you probably noticed in the above command, there is the <code class="language-plaintext highlighter-rouge">-w</code> parameter thing set to <code class="language-plaintext highlighter-rouge">0.5</code>. This an specific parameter for the method that controls the “strength” of the effect. With heavier values (near 1) the model will “overwrite” more of the original image and therefore we’ll lose some of details of SDXL (your skin will be softer, you’ll have less wrinkles, freckles, scars, etc) and the image will lose quality. On the other hand, with lower values (near 0) the artifacts couldn’t be removed. In my tests, most of the time, values around <code class="language-plaintext highlighter-rouge">0.5</code> were pretty much okay, though! But depending on each particular generation you’d need to increase it!</p><p>After running it, the fixed image will be saved by default on the same directory as your <code class="language-plaintext highlighter-rouge">CodeFormer</code> installation (inside the <code class="language-plaintext highlighter-rouge">results</code> folder).</p><p>The following image shows the fixed version of the above. Pretty cool, uh?</p><p><img data-src="https://media.githubusercontent.com/media/airlegend/airlegend.github.io/gh-pages/assets/img/posts/dreambooth/goodeyes1.png?raw=/true" alt="goodeyes" width="250" data-proofer-ignore></p><h2 id="closing-up"><span class="mr-2">Closing up</span><a href="#closing-up" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>I know there are more user friendly ways of doing the same thing I shared on this post. For example: <code class="language-plaintext highlighter-rouge">Kohya</code>, which is a tool that adds an abstraction layer from all the training code. You can take a look at this <a href="https://www.youtube.com/watch?v=TpuDOsuKIBo">Kohya tutorial</a> in case you’re interested. However, as a “code guy” myself, I find my way more straightforward to follow as long as one is familiar with Jupyter notebooks and some Python!</p><p>It’s very impressive how easy one can use state of the art techniques for something as foolish as generating photos of himself with this few amount of effort – free Google Colab, a pre-built training script, open sourced models and a few training photos – and get results of unthinkable quality just one or two years ago!</p><p>There’s only one question left: what we’ll have two years from now?</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='//categories/ml/'>ML</a>, <a href='//categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="//tags/maths/" class="post-tag no-text-decoration" >maths</a> <a href="//tags/programming/" class="post-tag no-text-decoration" >programming</a> <a href="//tags/python/" class="post-tag no-text-decoration" >python</a> <a href="//tags/pytorch/" class="post-tag no-text-decoration" >pytorch</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=How+I+generated+professional+headshots+for+my+LinkedIn+profile+-+Alvaro%27s+blog&url=https%3A%2F%2Fairlegend.github.io%2Fposts%2Fdreambooth%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=How+I+generated+professional+headshots+for+my+LinkedIn+profile+-+Alvaro%27s+blog&u=https%3A%2F%2Fairlegend.github.io%2Fposts%2Fdreambooth%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fairlegend.github.io%2Fposts%2Fdreambooth%2F&text=How+I+generated+professional+headshots+for+my+LinkedIn+profile+-+Alvaro%27s+blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/dreambooth/">How I generated professional headshots for my LinkedIn profile</a><li><a href="/posts/openchords/">The AI Coder: Building a website using AI</a><li><a href="/posts/lcm/">Latent Consistency Models: How to speedup image generation</a><li><a href="/posts/ai-development/">Some thoughts on the usage of AI for developing software: Is the end near?</a><li><a href="/posts/forward-mode-autodiferentiation/">The magic behind (forward mode) Automatic Differentiation</a></ul></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/lora/"><div class="card-body"> <em class="timeago small" data-ts="1698636780" > 2023-10-30 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>LoRA: How can I tune my model without an expensive GPU?</h3><div class="text-muted small"><p> Training neural networks can be really tedious. Both in terms of methodological complexity – tuning hyperparameters, syncing training runs, scheduling learning rates, etc. – and also hardware requi...</p></div></div></a></div><div class="card"> <a href="/posts/lcm/"><div class="card-body"> <em class="timeago small" data-ts="1701142380" > 2023-11-28 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Latent Consistency Models: How to speedup image generation</h3><div class="text-muted small"><p> In a previous post I briefly covered Diffusion Models. And as I pointed out, they have an important drawback that makes them slow at creating new images. We often have to wait minutes for an image ...</p></div></div></a></div><div class="card"> <a href="/posts/forward-mode-autodiferentiation/"><div class="card-body"> <em class="timeago small" data-ts="1647574380" > 2022-03-18 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>The magic behind (forward mode) Automatic Differentiation</h3><div class="text-muted small"><p> Demystifying Automatic Differentiation If you recall from highschool you’ll probably remember the definition of a derivative: [\begin{equation} f’(x) = \lim_{\epsilon \rightarrow 0} \frac{f(...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="//posts/lora/" class="btn btn-outline-primary" prompt="Older"><p>LoRA: How can I tune my model without an expensive GPU?</p></a> <a href="//posts/openchords/" class="btn btn-outline-primary" prompt="Newer"><p>The AI Coder: Building a website using AI</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/aalvaroir">Alvaro</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/programming/">programming</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/maths/">maths</a> <a class="post-tag" href="/tags/pytorch/">pytorch</a> <a class="post-tag" href="/tags/ai/">ai</a> <a class="post-tag" href="/tags/coding/">coding</a> <a class="post-tag" href="/tags/gpt/">gpt</a> <a class="post-tag" href="/tags/cv/">cv</a> <a class="post-tag" href="/tags/image/">image</a> <a class="post-tag" href="/tags/vision/">vision</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'], ], tags: 'ams' } }; // MathJax = { // tex: { // inlineMath: [ /* start/end delimiter pairs for in-line math */ // ['$','$'], // ['\\(','\\)'] // ], // displayMath: [ /* start/end delimiter pairs for display math */ // ['$$', '$$'], // ['\\[', '\\]'] // ] // }, // chtml: { // scale: 1.2, // global scaling factor for all expressions // }, // svg: { // minScale: .7, // }, // options: { // enableMenu: true, // set to false to disable the menu // menuOptions: { // settings: { // zoom: 'DoubleClick', // zscale: '300%', // zoom scaling factor // texHints: true, // collapsible: false, // true if complex math should be collapsible // explorer: false, // true if the expression explorere should be active // } // } // } // }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
